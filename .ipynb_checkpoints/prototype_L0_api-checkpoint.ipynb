{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The goal of the project is to build a L_0 regularization api for general application:\n",
    "Two approaches:\n",
    "    1. Construct a L_0 specific graph-building module (e.g. l0dense)\n",
    "    2. Construct a L_0 regularizer op\n",
    "\n",
    "The first one is much eaiser and thus I started from there:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### Copy from: https://github.com/tensorflow/tensorflow/blob/r1.7/tensorflow/python/layers/core.py\n",
    "    I intented to modify it so that the L0 function can be included"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# =============================================================================\n",
    "\n",
    "# pylint: disable=unused-import,g-bad-import-order\n",
    "\"\"\"Contains the core layers: Dense, Dropout.\n",
    "Also contains their functional aliases.\n",
    "\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "\n",
    "import six\n",
    "from six.moves import xrange  # pylint: disable=redefined-builtin\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.python.eager import context\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.framework import tensor_shape\n",
    "from tensorflow.python.layers import base\n",
    "from tensorflow.python.layers import utils\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import init_ops\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.ops import gen_math_ops\n",
    "from tensorflow.python.ops import nn\n",
    "from tensorflow.python.ops import nn_ops\n",
    "from tensorflow.python.ops import standard_ops\n",
    "from tensorflow.python.util.tf_export import tf_export\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Approach1: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "  def build(self, input_shape):\n",
    "    input_shape = tensor_shape.TensorShape(input_shape)\n",
    "    if input_shape[-1].value is None:\n",
    "      raise ValueError('The last dimension of the inputs to `Dense` '\n",
    "                       'should be defined. Found `None`.')\n",
    "    self.input_spec = base.InputSpec(min_ndim=2,\n",
    "                                     axes={-1: input_shape[-1].value})\n",
    "    \n",
    "   # create two sets of variables: one for parames, the other for gates\n",
    "        # one tricky things \n",
    "        # here is that the gates need to be defined with a placeholder within it\n",
    "        # ** so, I may need to develop a \"customized add_variable\"\n",
    "            (*1) \"\"add_variable_l0\"\" to be developed\n",
    "        \n",
    "    self.kernel_params = self.add_variable('kernel',\n",
    "                                    shape=[input_shape[-1].value, self.units],\n",
    "                                    initializer=self.kernel_initializer,\n",
    "                                    regularizer=self.kernel_regularizer,\n",
    "                                    constraint=self.kernel_constraint,\n",
    "                                    dtype=self.dtype,\n",
    "                                    trainable=True)\n",
    "    self.kernel_gates = self.\"\"add_variable_l0\"\"(*1)('kernel_gate',\n",
    "                                    shape=[input_shape[-1].value, self.units],\n",
    "                                    initializer=self.kernel_initializer,\n",
    "                                    regularizer=self.kernel_regularizer,\n",
    "                                    constraint=self.kernel_constraint,\n",
    "                                    dtype=self.dtype,\n",
    "                                    trainable=True)\n",
    "    \n",
    "    self.kernel = self.kernel_params * self. add_variable_l0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### layers.L0Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "@tf_export('layers.L0Dense')\n",
    "class L0Dense(base.Layer):\n",
    "    # To avoid potential conflict, the two arguments for regularizers are remove\n",
    "  def __init__(self, units,\n",
    "               activation=None,\n",
    "               use_bias=True,\n",
    "               kernel_initializer=None,\n",
    "               bias_initializer=init_ops.zeros_initializer(),                                             \n",
    "               kernel_constraint=None,\n",
    "               bias_constraint=None,\n",
    "               trainable=True,\n",
    "               name=None,\n",
    "               **kwargs):\n",
    "    super(Dense, self).__init__(trainable=trainable, name=name,\n",
    "                                activity_regularizer=activity_regularizer,\n",
    "                                **kwargs)\n",
    "    \n",
    "    # 3 properties related to regularizers are removed!\n",
    "        # involving regularize 1) activity; 2) weights; 3) biases\n",
    "        # *2 I can re-design it as the Boolean interface: to specify if L0 is used or not\n",
    "    self.units = units\n",
    "    self.activation = activation\n",
    "    self.use_bias = use_bias\n",
    "    self.kernel_initializer = kernel_initializer\n",
    "    self.bias_initializer = bias_initializer        \n",
    "    self.kernel_constraint = kernel_constraint\n",
    "    self.bias_constraint = bias_constraint\n",
    "    self.input_spec = base.InputSpec(min_ndim=2)\n",
    "\n",
    "  def build(self, input_shape):\n",
    "    input_shape = tensor_shape.TensorShape(input_shape)\n",
    "    if input_shape[-1].value is None:\n",
    "      raise ValueError('The last dimension of the inputs to `Dense` '\n",
    "                       'should be defined. Found `None`.')\n",
    "    self.input_spec = base.InputSpec(min_ndim=2,\n",
    "                                     axes={-1: input_shape[-1].value})\n",
    "    \n",
    "    # create two sets of variables: one for parames, the other for gates\n",
    "        # one tricky things \n",
    "        # here is that the gates need to be defined with a placeholder within it\n",
    "        # ** so, I may need to develop a \"customized add_variable\"\n",
    "        \n",
    "    self.kernel_params = self.add_variable('kernel',\n",
    "                                    shape=[input_shape[-1].value, self.units],\n",
    "                                    initializer=self.kernel_initializer,\n",
    "                                    regularizer=self.kernel_regularizer,\n",
    "                                    constraint=self.kernel_constraint,\n",
    "                                    dtype=self.dtype,\n",
    "                                    trainable=True)\n",
    "    self.kernel_gates = self.add_variable_l0('kernel_gate',\n",
    "                                    shape=[input_shape[-1].value, self.units],\n",
    "                                    initializer=self.kernel_initializer,\n",
    "                                    regularizer=self.kernel_regularizer,\n",
    "                                    constraint=self.kernel_constraint,\n",
    "                                    dtype=self.dtype,\n",
    "                                    trainable=True)\n",
    "    \n",
    "    self.kernel = self.kernel_params * self. add_variable_l0\n",
    "    \n",
    "    # create two sets of variables         \n",
    "    if self.use_bias:\n",
    "      self.bias = self.add_variable('bias',\n",
    "                                    shape=[self.units,],\n",
    "                                    initializer=self.bias_initializer,\n",
    "                                    regularizer=self.bias_regularizer,\n",
    "                                    constraint=self.bias_constraint,\n",
    "                                    dtype=self.dtype,\n",
    "                                    trainable=True)\n",
    "    else:\n",
    "      self.bias = None\n",
    "    self.built = True\n",
    "\n",
    "  def call(self, inputs):\n",
    "    inputs = ops.convert_to_tensor(inputs, dtype=self.dtype)\n",
    "    shape = inputs.get_shape().as_list()\n",
    "    if len(shape) > 2:\n",
    "      # Broadcasting is required for the inputs.\n",
    "      outputs = standard_ops.tensordot(inputs, self.kernel, [[len(shape) - 1],\n",
    "                                                             [0]])\n",
    "      # Reshape the output back to the original ndim of the input.\n",
    "      if not context.executing_eagerly():\n",
    "        output_shape = shape[:-1] + [self.units]\n",
    "        outputs.set_shape(output_shape)\n",
    "    else:\n",
    "      outputs = gen_math_ops.mat_mul(inputs, self.kernel)\n",
    "    if self.use_bias:\n",
    "      outputs = nn.bias_add(outputs, self.bias)\n",
    "    if self.activation is not None:\n",
    "      return self.activation(outputs)  # pylint: disable=not-callable\n",
    "    return outputs\n",
    "\n",
    "  def compute_output_shape(self, input_shape):\n",
    "    input_shape = tensor_shape.TensorShape(input_shape)\n",
    "    input_shape = input_shape.with_rank_at_least(2)\n",
    "    if input_shape[-1].value is None:\n",
    "      raise ValueError(\n",
    "          'The innermost dimension of input_shape must be defined, but saw: %s'\n",
    "          % input_shape)\n",
    "    return input_shape[:-1].concatenate(self.units)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### layers.l0dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "@tf_export('layers.dense')\n",
    "def dense(\n",
    "    inputs, units,\n",
    "    activation=None,\n",
    "    use_bias=True,\n",
    "    kernel_initializer=None,\n",
    "    bias_initializer=init_ops.zeros_initializer(),\n",
    "    kernel_regularizer=None,\n",
    "    bias_regularizer=None,\n",
    "    activity_regularizer=None,\n",
    "    kernel_constraint=None,\n",
    "    bias_constraint=None,\n",
    "    trainable=True,\n",
    "    name=None,\n",
    "    reuse=None):\n",
    "  layer = Dense(units,\n",
    "                activation=activation,\n",
    "                use_bias=use_bias,\n",
    "                kernel_initializer=kernel_initializer,\n",
    "                bias_initializer=bias_initializer,\n",
    "                kernel_regularizer=kernel_regularizer,\n",
    "                bias_regularizer=bias_regularizer,\n",
    "                activity_regularizer=activity_regularizer,\n",
    "                kernel_constraint=kernel_constraint,\n",
    "                bias_constraint=bias_constraint,\n",
    "                trainable=trainable,\n",
    "                name=name,\n",
    "                dtype=inputs.dtype.base_dtype,\n",
    "                _scope=name,\n",
    "                _reuse=reuse)\n",
    "  return layer.apply(inputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
